---
title: "Lake Okeechobee Recovery Ops Forecast"
output: 
  html_document: 
    toc: yes
    self_contained: true
    dev: png
    type: cairo
editor_options: 
  chunk_output_type: console
  markdown: 
    wrap: 72
---


------------------------------------------------------------------------

```{r date,echo=FALSE,message=FALSE,warning=FALSE}
up.date=format(Sys.time(),tz="America/New_York",usetz=T,"%F %R")
up.date=as.POSIXct(up.date,tz="America/New_York")

dst.check=lubridate::dst(as.POSIXct(up.date))

library(AnalystHelper)
library(reshape2)
library(plyr)
library(zoo)
library(flextable)

library(downloadthis)
library(labeling)

forFUN <- function(forecast_horizon,
                   I_forecast,
                   Q_forecast,
                   P_forecast,
                   E_forecast,
                   S,V){
  # Time step (Delta t)
  dt <- 1  # Assume daily time steps
  A <- get_LOK_area(V[1])
  # Simulate future volumes and stages
  for (t in 1:forecast_horizon) {
    # Get the area based on current volume
    A_t <- get_LOK_area(V[t])
    A[t+1] <- A_t
    # Compute the new volume using the water balance equation
    V[t + 1] <- V[t] + dt * (I_forecast[t] - Q_forecast[t] + A[t] * (P_forecast[t] - E_forecast[t]))
    
    # Update the stage based on the new volume
    S[t + 1] <- get_LOK_stage(V[t + 1])
  }
  
  # Results
  rslt <- data.frame(
    Time = 1:(forecast_horizon + 1),
    Stage = S,
    Volume = V,
    Area = A
  )
  return(rslt)
}

forFUN_scenario <- function(CRE.Q,SLE.Q,EAA.Q, inflow.Q, ET,RF=NULL,STG){
  I_forecast <- inflow.Q #Q.dat$Inflow.median 
  Q_forecast <- CRE.Q+SLE.Q+EAA.Q
  P_forecast <- if(is.null(RF)){rep(0,num.weeks*7)}else{RF}
  E_forecast <- ET
  
  forecast_horizon <- num.weeks*7; # Days
  # Start with an initial stage
  S <- numeric(forecast_horizon + 1)  # Stage
  V <- numeric(forecast_horizon + 1)  # Volume
  # A <- numeric(forecast_horizon + 1)  # Area
  S[1] <- STG  # Initial stage 
  V[1] <- get_LOK_volume(S[1])  # Compute initial volume (m3)
  
  LOK_HMF <- forFUN(forecast_horizon,
                    I_forecast,
                    Q_forecast,
                    P_forecast,
                    E_forecast,
                    S,
                    V)
  
  LOK_HMF$Date_forecast <- (TODAY-(1*86400))+as.numeric((LOK_HMF$Time*86400))
  LOK_HMF <- cbind(LOK_HMF,data.frame(
    CRE = c(NA,CRE.Q),
    SLE = c(NA,SLE.Q),
    EAA = c(NA,EAA.Q),
    QT = c(NA,Q_forecast),
    Inflow = c(NA,inflow.Q))
  )
  
  return(LOK_HMF)
  
}

heck_nice <- function(x,round){
      e <- floor(log10(x))
    f <- x/(10^e)
    if (round) {
        if (f < 1.5) 
            nf <- 1
        else if (f < 3) 
            nf <- 2
        else if (f < 7) 
            nf <- 5
        else nf <- 10
    }
    else {
        if (f <= 1) 
            nf <- 1
        else if (f <= 2) 
            nf <- 2
        else if (f <= 5) 
            nf <- 5
        else nf <- 10
    }
    nf * (10^e)
}
heckbert_labs <- function(dmin,dmax,m){
  
    range <- heck_nice((dmax - dmin), FALSE)
    lstep <- heck_nice(range/(m - 1), TRUE)
    lmin <- floor(dmin/lstep) * lstep
    lmax <- ceiling(dmax/lstep) * lstep
    seq(lmin, lmax, by = lstep)
}


## LOK specific
num.weeks <- 20
day.num <- seq(1,num.weeks*7,1)
week.num <- sort(rep(1:num.weeks,7))
Q.fac=c(0.2,0.4,0.6,0.8,1.2,1.7,2.1)

## Dates
TODAY <- date.fun(Sys.Date())
YEST <- TODAY - 86400
TODAY.DOY <- TODAY|>
  format("%j")|>
  as.numeric()

EDate <- date.fun(TODAY + max(day.num)*86400)
EDate.DOY <- EDate|>
  format("%j")|>
  as.numeric()

## LOSOM Schedule
LOSOM.sch.bk = data.frame(
  day = c(1, 2, 2, 2, 1, 2, 2, 1, 2, 2, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1,
          1, 2, 22, 2, 2, 1, 1, 1, 1, 2, 2, 2, 1, 1, 1, 1, 2, 1, 2, 1, 1), 
  month = c(1, 4, 6, 11, 1, 6, 11, 1, 6, 11, 1, 4, 5, 6, 6, 10, 10, 11, 12,
            1, 4, 5, 6, 6, 8, 10, 11, 1, 4, 5, 6, 6, 10, 11, 1, 4, 5, 6, 6,
            10, 10, 11, 12), 
  variable = c("ZONE.A", "ZONE.A", "ZONE.A", "ZONE.A", "ZONE.BC", "ZONE.BC", 
               "ZONE.BC",  "ZONE.BXX", "ZONE.BXX", "ZONE.BXX", "ZONE.D",
               "ZONE.D", "ZONE.D",  "ZONE.D", "ZONE.D", "ZONE.D", "ZONE.D",
               "ZONE.D", "ZONE.D", "ZONE.D1",  "ZONE.D1", "ZONE.D1", "ZONE.D1", 
               "ZONE.D1", "ZONE.D1", "ZONE.D1", "ZONE.D1", "ZONE.D2", 
               "ZONE.D2", "ZONE.D2", "ZONE.D2", "ZONE.D2", "ZONE.D2",
               "ZONE.D2", "ZONE.D3", "ZONE.D3", "ZONE.D3", "ZONE.D3",
               "ZONE.D3", "ZONE.D3", "ZONE.D3", "ZONE.D3", "ZONE.D3"), 
  value = c(17.25, 17.25, 16.5, 17.25, 16.85, 16.1, 16.85, 16.85, 16.1, 16.85,
            12.16,  11.7, 10.95, 10.5, 10.5, 13, 13, 12.8, 12.4, 14.49, 13.94,
            13.04, 12.5, 14.5, 14.5, 15.5, 15.5, 13.66, 13.2, 12.45, 12, 14.5,
            14.5, 15, 12.16, 11.7, 10.95, 10.5, 10.5, 13, 13, 12.8, 12.4)
)
 
# LOSOM.sch.bk$value = LOSOM.sch.bk$value - 1.25 # NAVD to NGVD conversion

CurWY <- WY(Sys.Date())
vals <- c(-1,0,1)
fill=data.frame(Date=seq(date.fun(paste(CurWY+min(vals),"01-01",sep="-")),date.fun(paste(CurWY+max(vals),"04-30",sep="-")),"1 days"))

n_row_vals = nrow(LOSOM.sch.bk)
tot_row = n_row_vals*length(vals)
date_mat =matrix(NA,nrow=tot_row,ncol=1) # data.frame(Date = rep(NA,tot_row))

CurWY <- WY(Sys.Date())
for (i in seq_along(vals)) {
  start_idx <- (i - 1) * n_row_vals + 1
  end_idx <- i * n_row_vals
  date_mat[start_idx:end_idx, 1] <- date.fun(
    paste(CurWY + vals[i], LOSOM.sch.bk$month, LOSOM.sch.bk$day, sep = "-")
  )
}
date_mat = data.frame(Date = date.fun(as.POSIXct(date_mat,origin = "1970-01-01")))

LOSOM.sch.bk = cbind(LOSOM.sch.bk,date_mat)|>
  dcast(Date~variable,value.var = "value",mean)|>
  merge(fill,"Date",all.y=T)

LOSOM.sch.bk[-1] = lapply(LOSOM.sch.bk[-1],dat.interp);

## Lake Recovery started Dec 7
lake.rec <- date.fun("2024-12-07")

```

`r paste("Updated:",up.date, ifelse(dst.check==T,"EDT","EST"))`

<!-- ![](https://github.com/sccf-tech/CRE_Conditions/actions/workflows/RegionalReport.yaml/badge.svg) -->

------------------------------------------------------------------------

## Purpose

This webpage/report is intended to share potential scenario forecasts associated with Lake Okeechobee Recovery Operations in the late-2024 to mid-2025 time period. 

## Framework

This forecasts are based on a hydrological modeling framework for lake water level management using a simple water balance equation (below).

$$\frac{\Delta V}{\Delta t} = I_t -Q_t + A_t\times (P_t - E_t) $$

Where

- $V_t$ (ac-ft) and $A_t$ (acres) are volume/storage and area based on the stage-volume-area relationships specific to Lake Okeechobee based on recent bathymetry

- $P_t$ ($ft \; d^{-1}$) and $E_t$ ($ft \; d^{-1}$) are precipitation and evapotranspiration  
  - Based on historic data (last 10 water years) spatially averaged from monitoring locations (see [Data Sources](#datasource), below). 
- $I_t$ ($ac\mbox{-}ft \; d^{-1}$) is inflow discharges to the lake based on historic discharges
- $Q_t$ ($ac\mbox{-}ft \; d^{-1}$) is outflow discharges from the lake based on a combination of historic discharges and pulse releases depending on the scenario. 

### Stage-Volume-Area

Using the most recent 15 meter spatial resolution bathymetric data of Lake Okeechobee (2009) we can estimate/derive the Stage-Volume-Area relationship using to calculate/estimate the lake area and storage volume of the lake at a given stage elevation. 

```{r,include=F}
LOK.stg.area.vol <- data.frame(STG29.ft = c(8, 8.1, 8.2, 8.3, 8.4, 8.5, 8.6, 8.7, 8.8, 8.9, 9, 9.1, 9.2, 9.3, 9.4, 9.5, 9.6, 9.7, 9.8, 9.9, 
                                            10, 10.1, 10.2, 10.3, 10.4, 10.5, 10.6, 10.7, 10.8, 10.9, 11, 11.1, 11.2, 11.3, 11.4, 11.5, 11.6, 
                                            11.7, 11.8, 11.9, 12, 12.1, 12.2, 12.3, 12.4, 12.5, 12.6, 12.7, 12.8, 12.9, 13, 13.1, 13.2, 13.3,
                                            13.4, 13.5, 13.6, 13.7, 13.8, 13.9, 14, 14.1, 14.2, 14.3, 14.4, 14.5, 14.6, 14.7, 14.8, 14.9, 15, 
                                            15.1, 15.2, 15.3, 15.4, 15.5, 15.6, 15.7, 15.8, 15.9, 16, 16.1, 16.2, 16.3, 16.4, 16.5, 16.6, 16.7, 
                                            16.8, 16.9, 17, 17.1, 17.2, 17.3, 17.4, 17.5, 17.6, 17.7, 17.8, 17.9, 18, 18.1, 18.2, 18.3, 18.4, 
                                            18.5, 18.6, 18.7, 18.8, 18.9, 19), 
                               area.acres = c(286931.945053453, 288659.478508059, 
                                              290411.157627961, 292047.614321307, 293675.353339772, 295253.481905787, 
                                              296822.778090672, 298388.977206849, 300155.740198421, 302170.26868662, 
                                              304764.407848178, 310489.855532731, 313386.475071421, 315540.1995921, 
                                              317525.994165065, 319582.161021447, 321248.269280014, 322695.862135306, 
                                              324076.122422765, 325456.268003976, 326836.987116428, 328229.750384967, 
                                              329593.779738272, 330982.87240686, 332387.450418988, 333816.174096412, 
                                              335298.695004354, 336822.739574231, 338344.891491008, 339800.456430566, 
                                              341224.82127055, 342660.255263508, 344109.970184396, 345572.417498861, 
                                              347044.729550691, 348537.115195999, 350038.677341181, 351531.808577104, 
                                              353051.207543918, 354572.040338838, 356089.604005678, 357602.350010083, 
                                              359200.724228948, 360818.598510047, 362454.252259654, 364149.782670945, 
                                              365949.982533937, 367881.635757639, 369946.462935778, 372155.361161956, 
                                              374533.795223326, 377078.668051179, 379678.657231407, 382420.882159699, 
                                              385504.358177095, 388930.060286707, 392583.798418215, 396413.094462957, 
                                              400303.471584993, 404198.838428835, 407989.363761606, 411624.290068369, 
                                              415015.580303449, 418200.227231968, 421175.822022708, 423888.338032654, 
                                              426403.444589038, 428635.169358655, 430523.23420795, 432054.7920371, 
                                              433346.499100764, 434485.532147757, 435501.5427433, 436375.088178282, 
                                              437176.311323624, 437917.657807281, 438569.648123405, 439144.899959324, 
                                              439633.66328392, 440064.958778048, 440467.405650694, 440829.131805144, 
                                              441159.715213144, 441461.105880915, 441736.630289664, 441970.745742727, 
                                              442175.840514935, 442366.252887343, 442530.684294479, 442690.240686057, 
                                              442841.939699616, 442980.676907103, 443098.422871125, 443206.992335272, 
                                              443297.782330911, 443372.742864265, 443439.444547732, 443496.453553206, 
                                              443546.637536898, 443591.545033161, 443634.101051332, 443670.520285211, 
                                              443705.563044109, 443738.827856156, 443770.658840098, 443801.342761555, 
                                              443828.528142435, 443857.319410793, 443883.701847934, 443912.091644422, 
                                              443937.957903445), 
                               volume.acft = c(1324860.22411819, 1353639.65659936, 
                                               1382593.93009713, 1411717.15617127, 1441003.87085337, 1470450.78888693, 
                                               1500055.11623118, 1529815.30778325, 1559740.61171264, 1589854.78728863, 
                                               1620194.25551187, 1650947.46392218, 1682151.27385851, 1713601.20633191, 
                                               1745253.97015856, 1777111.20116852, 1809155.18274835, 1841353.23288074, 
                                               1873692.41759043, 1906168.75974129, 1938783.656838, 1971537.38724134, 
                                               2004429.01735657, 2037457.78571277, 2070626.2044396, 2103936.05723706, 
                                               2137391.77848396, 2170997.72519194, 2204757.28116795, 2238664.92050973, 
                                               2272715.88548058, 2306910.15539802, 2341248.5814368, 2375733.04084967, 
                                               2410363.96776856, 2445143.40755672, 2480071.75389886, 2515149.92367027, 
                                               2550378.71696294, 2585760.01104207, 2621293.60380629, 2656978.12742158, 
                                               2692817.6508199, 2728818.47826856, 2764982.4441325, 2801311.76752278, 
                                               2837815.84191407, 2874506.95449363, 2911397.90170825, 2948501.76235325, 
                                               2985835.28955157, 3023415.10883431, 3061252.53903132, 3099355.30968831, 
                                               3137747.83031165, 3176466.64214281, 3215540.40873928, 3254989.61252921, 
                                               3294826.00490399, 3335051.81817497, 3375662.02661812, 3416644.74243024, 
                                               3457979.04351222, 3499641.99022086, 3541612.74078199, 3583868.2559578, 
                                               3626385.73812284, 3669140.61614009, 3712101.75616383, 3755233.0196693, 
                                               3798504.67128526, 3841897.60589953, 3885398.03186488, 3928992.82624874, 
                                               3972670.715268, 4016426.21532669, 4060251.13860002, 4104137.65900201, 
                                               4148077.02174913, 4192062.29042834, 4236089.23215342, 4280154.5735577, 
                                               4324254.12648205, 4368385.67058007, 4412545.88931767, 4456731.59849216, 
                                               4500939.15588951, 4545166.58694607, 4589411.5620276, 4633672.87905449, 
                                               4677949.52451478, 4722240.80267177, 4766544.97279963, 4810860.52004886, 
                                               4855185.8935682, 4899519.70382097, 4943860.51241232, 4988207.45544256, 
                                               5032559.74061588, 5076916.84183154, 5121278.27393572, 5165643.64708161, 
                                               5210012.52714814, 5254384.85241813, 5298760.46561124, 5343139.18954987, 
                                               5387520.7699878, 5431905.1172056, 5476292.28342187, 5520682.23831967, 
                                               5565074.85758918))

WCP.tab7_8 <- data.frame(
  STG.FT = c(8, 8.1, 8.2, 8.3, 8.4, 8.5, 8.6, 8.7, 8.8, 8.9, 9, 9.1, 9.2, 
             9.3, 9.4, 9.5, 9.6, 9.7, 9.8, 9.9, 10, 10.1, 10.2, 10.3, 10.4,
             10.5, 10.6, 10.7, 10.8, 10.9, 11, 11.1, 11.2, 11.3, 11.4, 11.5,
             11.6, 11.7, 11.8, 11.9, 12, 12.1, 12.2, 12.3, 12.4, 12.5, 12.6,
             12.7, 12.8, 12.9, 13, 13.1, 13.2, 13.3, 13.4, 13.5, 13.6, 13.7, 
             13.8, 13.9, 14, 14.1, 14.2, 14.3, 14.4, 14.5, 14.6, 14.7, 14.8, 
             14.9, 15, 15.1, 15.2, 15.3, 15.4, 15.5, 15.6, 15.7, 15.8, 15.9, 
             16, 16.1, 16.2, 16.3, 16.4, 16.5, 16.6, 16.7, 16.8, 16.9, 17, 
             17.1, 17.2, 17.3, 17.4, 17.5, 17.6, 17.7, 17.8, 17.9, 18, 18.1,
             18.2, 18.3, 18.4, 18.5, 18.6, 18.7, 18.8, 18.9, 19, 19.1, 19.2, 
             19.3, 19.4, 19.5, 19.6, 19.7, 19.8, 19.9, 20),
  STORE.ACFT = c(1329506 , 1356107 , 1382985 , 1410137 , 1437563 , 1465259 , 
                 1493225 , 1521460 , 1549960 , 1578726 , 1607755 , 1637045 , 
                 1666596 , 1696405 , 1726471 , 1756792 , 1787366 , 1818193 , 
                 1849270 , 1880596 , 1912169 , 1943988 , 1976050 , 2008355 , 
                 2040901 , 2073686 , 2106708 , 2139967 , 2173459 , 2207185 , 
                 2241141 , 2275328 , 2309742 , 2344382 , 2379247 , 2414335 ,
                 2449644 , 2485174 , 2520921 , 2556886 , 2593065 , 2629458 ,
                 2666063 , 2702878 , 2739901 , 2777132 , 2814567 , 2852207 , 
                 2890049 , 2928092 , 2966333 , 3004772 , 3043407 , 3082235 , 
                 3121257 , 3160469 , 3199871 , 3239460 , 3279235 , 3319195 , 
                 3359338 , 3399662 , 3440166 , 3480848 , 3521707 , 3562740 , 
                 3603947 , 3645325 , 3686873 , 3728590 , 3770474 , 3812523 , 
                 3854735 , 3897110 , 3939644 , 3982338 , 4025189 , 4068196 ,
                 4111356 , 4154669 , 4198133 , 4241745 , 4285506 , 4329412 , 
                 4373463 , 4417656 , 4461990 , 4506464 , 4551076 , 4595825 , 
                 4640708 , 4685724 , 4730871 , 4776149 , 4821554 , 4867087 , 
                 4912744 , 4958525 , 5004428 , 5050450 , 5096592 , 5142851 , 
                 5189225 , 5235712 , 5282312 , 5329023 , 5375843 , 5422770 ,
                 5469802 , 5516939 , 5564179 , 5611519 , 5658959 , 5706497 ,
                 5754130 , 5801858 , 5849680 , 5897592 , 5945594 , 5993684 ,
                 6041861 ))
```

```{r LOK_SAV,echo=FALSE,results='hide',fig.width=6.5,fig.height=5,fig.align='center',fig.cap="Stage-Volume-Area relationships for Lake Okeechobee"}
par(family="serif",mar=c(1,3,0.5,0.5),oma=c(2,2.5,0.5,0.1));
layout(matrix(1:2,2,1))

xlim.val=c(8,19);by.x=1;xmaj=seq(xlim.val[1],xlim.val[2],by.x);xmin=seq(xlim.val[1],xlim.val[2],by.x/2)

ylim.val=c(1300e3,6000e3);by.y=1000e3;ymaj=seq(ylim.val[1],ylim.val[2],by.y);ymin=seq(ylim.val[1],ylim.val[2],by.y/2)
plot(volume.acft~STG29.ft,LOK.stg.area.vol,ylim=ylim.val,xlim=xlim.val,type="n",ann=F,axes=F)
abline(h=ymaj,v=xmaj,lwd=1,col="grey",lty=3)
lines(volume.acft~STG29.ft,LOK.stg.area.vol,lwd=2,col="black")
lines(STORE.ACFT~STG.FT, WCP.tab7_8,col="indianred1",lwd=2,lty=2)
axis_fun(1,xmaj,xmin,xmaj,line=-0.5)
axis_fun(2,ymaj,ymin,ymaj/1e3)
box(lwd=1)
# mtext(side=1,"Month",line=2,cex=1.25)
mtext(side=2,"Storage Volume\n(x10\u00B3 Ac-Ft)",line=3,cex=1)
legend("topleft",legend = c("LOSOM WCP Table 7-8", "2009 Bathymetry Estimate"),
       pch=c(NA),lty=c(2,1),lwd=c(2),
       col=c("indianred1","black"),
       pt.bg=NA,pt.cex=1,
       ncol=1,cex=0.75,bty="n",y.intersp=1,x.intersp=0.75,xjust=0.5,yjust=0.5)

ylim.val=c(250e3,450e3);by.y=50e3;ymaj=seq(ylim.val[1],ylim.val[2],by.y);ymin=seq(ylim.val[1],ylim.val[2],by.y/2)
plot(area.acres~STG29.ft,LOK.stg.area.vol,ylim=ylim.val,xlim=xlim.val,type="n",ann=F,axes=F)
abline(h=ymaj,v=xmaj,lwd=1,col="grey",lty=3)
lines(area.acres~STG29.ft,LOK.stg.area.vol,lwd=2,col="black")
axis_fun(1,xmaj,xmin,xmaj,line=-0.5)
axis_fun(2,ymaj,ymin,ymaj/1e3)
box(lwd=1)
mtext(side=1,"Stage (Ft, NGVD29)",line=1.75,cex=1)
mtext(side=2,"Area\n(x10\u00B3 Acres)",line=3,cex=1)

```


## Scenarios

To evaluate the change in lake stage several scenarios were considered. Each scenario is intended to understand how the lake stage could change given changes to lake inflows and outflows. When using historic data (i.e. ET, inflow, and outflow discharges to EAA) period of record median values were used.

```{r , echo=F}

cap.val <- "Lake Okeechobee Stage Forecast Scenarios"
data.frame(Scenario =c(1:6),
           CRE = c(2100),
           SLE = c(1400,1400,1400,700,0,150),
           EAA = c(0, "Historic Median",rep("Historic Median + 300 cfs (after 1 Feb)",4)))|>
  flextable()|>
  width(width=c(0.5,0.75,0.75,2.75))|>
  align(align="center",part="all")|>
  padding(padding=1,part="all")|>
  footnote(j=2:3,part="header",
           value=as_paragraph("Based on weekly average pulse releases"),ref_symbols =c(" A "))|>
  add_header_lines(values=cap.val)%>%align(align="center",part="header")%>%fontsize(size=13,part="header")|>
  font(fontname="Times New Roman",part="all")|>
  fontsize(size=12,part="body")|>
  fontsize(size=13,part="header")|>
  bold(part="header")

```

<br>

```{r, echo=F}

cap.val <- "Example Northern Estuary Pulse Releases"
data.frame(Scenario =c(1:7),
           CRE = Q.fac*2100,
           SLE_1400 = Q.fac*1400,
           SLE_700 = Q.fac*700,
           SLE_150 = Q.fac*150)|>
  flextable()|>
  width(width=c(0.5,1,1,1,1))|>
  align(align="center",part="all")|>
  padding(padding=1,part="all")|>
  set_header_labels("CRE" = "CRE\n(2100 cfs)",
                    "SLE_1400"="SLE\n(1400 cfs)",
                    "SLE_700"="SLE\n(700 cfs)",
                    "SLE_150"="SLE\n(150 cfs)")|>
  add_header_lines(values=cap.val)%>%align(align="center",part="header")%>%fontsize(size=13,part="header")|>
  font(fontname="Times New Roman",part="all")|>
  fontsize(size=12,part="body")|>
  fontsize(size=13,part="header")|>
  bold(part="header")

```

<br>
Upper and lower bounds of scenario forecasts were calculated using historically observed data based on management objectives during wetter and drier conditions, respectively. Using daily observed discharge, rainfall and ET values between May 2015 to current, the upper (wetter) bounds used the 10th percentile discharge volume to the EAA (plus amount dictated by each respective scenario), 90th percentile for lake inflows, 10th percentile for ET and 90th percentile for rainfall to estimate the change in storage. Conversely for drier conditions (lower bounds) the 90th percentile discharge volume to the EAA, 10th percentile for lake inflows, 90th percentile for ET and 10th percentile for rainfall to estimate the change in storage.    


## Results {.tabset}

```{r data, include=FALSE}

dates = date.fun(c("2015-05-01","2025-04-30"))

# Stage Data --------------------------------------------------------------
LOK.da.dbkeys <- data.frame(
  DBKEY=c("06832","00268"),Priority=c("P2","P1")
)
# DBHYDRO.meta.byDBKEY(LOK.da.dbkeys$DBKEY)

LOK_da_stg_list <- lapply(LOK.da.dbkeys$DBKEY, function(dbkey) {
  # Attempt to retrieve data and handle errors
  tryCatch({
    tmp <- DBHYDRO_daily(dates[1], dates[2], dbkey)
    tmp$DBKEY <- as.character(dbkey)
    #setTxtProgressBar(pb, i)
    tmp
  }, error = function(e) {
    message(sprintf("Skipping DBKEY %s due to error: %s", dbkey, e$message))
    NULL  # Return NULL if there's an error
  })
})

# Remove any NULL elements (i.e., those that caused errors) from the list
LOK_stg_list <- Filter(Negate(is.null), LOK_da_stg_list)

# Combine all data frames in the list into one data frame
LOK.stg.da <- do.call(rbind, LOK_stg_list)|>
  merge(LOK.da.dbkeys, by = "DBKEY")|># Merge the combined data with the dbkeys data frame
  mutate(Date.EST = date.fun(Date))

LOK.stg.da <- dcast(LOK.stg.da,Date.EST~Priority,value.var = "Data.Value",mean,na.rm=T)
if(sum(names(LOK.stg.da)%in%c("P1"))==0){LOK.stg.da$P1 <- NA}
LOK.stg.da$STG29 <- with(LOK.stg.da,ifelse(is.na(P1)==T,P2,P1))

if(is.na(subset(LOK.stg.da,Date.EST==YEST)$STG29)){
  map.url <- paste0("https://w3.saj.usace.army.mil/h2o/reports/StatusDaily/archive/",format(YEST,"%m%d"),"/StatusDaily.htm")
  mapdata <- readLines(map.url)
  val <- grep("../plots/ok8hhp.pdf",mapdata)
  LakeStage <- as.numeric(strsplit(mapdata[val[1]],"\\s+")[[1]][6])
  
  LOK.stg.da[LOK.stg.da$Date.EST==YEST,"STG29"] <- LakeStage
  
}

# tail(LOK.stg.da)
# Interpolation functions
get_LOK_area <- approxfun(LOK.stg.area.vol$STG29.ft, LOK.stg.area.vol$area.acres, rule = 2)    # Volume -> Area
get_LOK_stage <- approxfun(LOK.stg.area.vol$volume.acft, LOK.stg.area.vol$STG29.ft, rule = 2)  # Volume -> Stage
get_LOK_volume <- approxfun(LOK.stg.area.vol$STG29.ft, LOK.stg.area.vol$volume.acft, rule = 2) # Stage -> Volume

# LOK.stg.da$volume.acft <- get_LOK_volume(LOK.stg.da$STG29)
# LOK.stg.da$area.acres <- get_LOK_area(LOK.stg.da$STG29)

LOK.stg.da <- LOK.stg.da[order(LOK.stg.da$Date.EST),]
LOK.stg.da <- LOK.stg.da|>
  mutate(
    volume.acft = get_LOK_volume(STG29),
    area.acres = get_LOK_area(STG29),
    CY = as.numeric(format(Date.EST,"%Y")),
    month = as.numeric(format(Date.EST,"%m")),
    DOY = as.numeric(format(Date.EST,"%j")),
    WY=WY(Date.EST)
  )

# ET Data -----------------------------------------------------------------
sdate <- dates[1]# date.fun(Sys.Date()-(365*4))
edate <- dates[2]# date.fun(Sys.Date())

LOK.etpi.dbkeys <- data.frame(
  DBKEY=c("WZ688","UT743","UT748","TW080","UA627")
)
# DBHYDRO.meta.byDBKEY(LOK.etpi.dbkeys$DBKEY)

LOK_da_etpi_list <- lapply(LOK.etpi.dbkeys$DBKEY, function(dbkey) {
  # Attempt to retrieve data and handle errors
  tryCatch({
    tmp <- DBHYDRO_daily(sdate, edate, dbkey)
    tmp$DBKEY <- as.character(dbkey)
    #setTxtProgressBar(pb, i)
    tmp
  }, error = function(e) {
    message(sprintf("Skipping DBKEY %s due to error: %s", dbkey, e$message))
    NULL  # Return NULL if there's an error
  })
})

# Remove any NULL elements (i.e., those that caused errors) from the list
LOK_etpi_list <- Filter(Negate(is.null), LOK_da_etpi_list)

# Combine all data frames in the list into one data frame
LOK.etpi.da <- do.call(rbind, LOK_etpi_list)|>
  mutate(Date.EST = date.fun(Date),
         month = as.numeric(format(Date,"%m")),
         CY = as.numeric(format(Date,"%Y")),
         day = as.numeric(format(Date,"%d")),
         DOY = as.numeric(format(Date,"%j")))
LOK.etpi.da$Data.Value <- with(LOK.etpi.da,ifelse(Data.Value>1|Data.Value==0,NA,Data.Value))

site.month.mean <- ddply(LOK.etpi.da,c("CY","day","month","DOY"),summarise,
      mean.ETPI = mean(Data.Value/12,na.rm=T)); #spatially averaged data
site.month.mean$mean.ETPI <- with(site.month.mean,ifelse(mean.ETPI>0.2,NA,mean.ETPI))

overall_ETPI_mean <- ddply(site.month.mean,c("month","day"),summarise,
        mean.ETPI_ft = mean(mean.ETPI,na.rm=T),
        SE.ETPI_ft = SE(mean.ETPI),
        sd.ETPI_ft = sd(mean.ETPI,na.rm=T),
        med.ETPI_ft = median(mean.ETPI,na.rm=T),
        Q10.ETPI_ft=quantile(mean.ETPI,na.rm=T,prob=c(0.10)),
        Q2.ETPI_ft=quantile(mean.ETPI,na.rm=T,prob=c(0.25)),
        Q3.ETPI_ft=quantile(mean.ETPI,na.rm=T,prob=c(0.75)),
        Q90.ETPI_ft=quantile(mean.ETPI,na.rm=T,prob=c(0.90)),
        N.val = N.obs(mean.ETPI))|>
  mutate(UCI = mean.ETPI_ft + qnorm((1-0.95)/2)* SE.ETPI_ft,
         LCI = mean.ETPI_ft - qnorm((1-0.95)/2)* SE.ETPI_ft,
         DOY = as.numeric(format(date.fun(paste(2024,month,day,sep="-")),"%j")))

overall_ETPI_mean2 <- overall_ETPI_mean[,!(names(overall_ETPI_mean)%in%c("month","day","N.val"))]

# LOK.stg.da.ET <- merge(LOK.stg.da,overall_ETPI_mean2,"DOY")
# LOK.stg.da.ET <- LOK.stg.da.ET[order(LOK.stg.da.ET$Date.EST),]
# 
# LOK.stg.da.ET$ETLoss <- with(LOK.stg.da.ET,area.acres*mean.ETPI_ft)
# LOK.stg.da.ET$ETLoss.UL <- with(LOK.stg.da.ET,area.acres*(UCI))
# LOK.stg.da.ET$ETLoss.LL <- with(LOK.stg.da.ET,area.acres*(LCI))
# 
# LOK.stg.da.ET$ETLoss.med <- with(LOK.stg.da.ET,area.acres*med.ETPI_ft)
# LOK.stg.da.ET$ETLoss.Q2 <- with(LOK.stg.da.ET,area.acres*(Q2.ETPI_ft))
# LOK.stg.da.ET$ETLoss.Q3 <- with(LOK.stg.da.ET,area.acres*(Q3.ETPI_ft))
# LOK.stg.da.ET$ETLoss.Q10 <- with(LOK.stg.da.ET,area.acres*(Q10.ETPI_ft))
# LOK.stg.da.ET$ETLoss.Q90 <- with(LOK.stg.da.ET,area.acres*(Q90.ETPI_ft))
# 
# LOK.stg.da.ET$ETLoss_30d <- zoo::rollapply(LOK.stg.da.ET$ETLoss,30,mean,align="right",fill=NA)
# LOK.stg.da.ET$ETLoss.UL_30d <- zoo::rollapply(LOK.stg.da.ET$ETLoss.UL,30,mean,align="right",fill=NA)
# LOK.stg.da.ET$ETLoss.LL_30d <- zoo::rollapply(LOK.stg.da.ET$ETLoss.LL,30,mean,align="right",fill=NA)

# Rainfall -------------------------------------------------------------------
LOK.rf.dbkeys <- data.frame(
  DBKEY=c("16021","13081","12524","12515")
)
# DBHYDRO.meta.byDBKEY(LOK.rf.dbkeys$DBKEY)

LOK_da_rf_list <- lapply(LOK.rf.dbkeys$DBKEY, function(dbkey) {
  # Attempt to retrieve data and handle errors
  tryCatch({
    tmp <- DBHYDRO_daily(sdate, edate, dbkey)
    tmp$DBKEY <- as.character(dbkey)
    #setTxtProgressBar(pb, i)
    tmp
  }, error = function(e) {
    message(sprintf("Skipping DBKEY %s due to error: %s", dbkey, e$message))
    NULL  # Return NULL if there's an error
  })
})

# Remove any NULL elements (i.e., those that caused errors) from the list
LOK_rf_list <- Filter(Negate(is.null), LOK_da_rf_list)

# Combine all data frames in the list into one data frame
LOK.rf.da <- do.call(rbind, LOK_rf_list)|>
  mutate(Date.EST = date.fun(Date),
         month = as.numeric(format(Date,"%m")),
         CY = as.numeric(format(Date,"%Y")),
         day = as.numeric(format(Date,"%d")),
         DOY = as.numeric(format(Date,"%j")))

site.month.rf.mean <- ddply(LOK.rf.da,c("CY","day","month","DOY"),summarise,
      mean.RF = mean(Data.Value/12,na.rm=T));# spatially average mean rainfall in feet

overall_rf_mean <- ddply(site.month.rf.mean,c("month","day"),summarise,
        mean.RF_ft = mean(mean.RF,na.rm=T),
        SE.RF_ft = SE(mean.RF),
        sd.RF_ft = sd(mean.RF,na.rm=T),
        med.RF_ft = median(mean.RF,na.rm=T),
        Q10.RF_ft=quantile(mean.RF,na.rm=T,prob=c(0.10)),
        Q2.RF_ft=quantile(mean.RF,na.rm=T,prob=c(0.25)),
        Q3.RF_ft=quantile(mean.RF,na.rm=T,prob=c(0.75)),
        Q90.RF_ft=quantile(mean.RF,na.rm=T,prob=c(0.90)),
        N.val = N.obs(mean.RF))|>
  mutate(UCI = mean.RF_ft + qnorm((1-0.95)/2)* sd.RF_ft,
         LCI = mean.RF_ft - qnorm((1-0.95)/2)* sd.RF_ft,
         DOY = as.numeric(format(date.fun(paste(2024,month,day,sep="-")),"%j")))

overall_rf_mean2 <- overall_rf_mean[,!(names(overall_rf_mean)%in%c("month","day","N.val"))]

# LOK.stg.da.RF <- merge(LOK.stg.da,overall_rf_mean2,"DOY")
# LOK.stg.da.RF <- LOK.stg.da.RF[order(LOK.stg.da.RF$Date.EST),]
# 
# LOK.stg.da.RF$RF.vol.mean <- with(LOK.stg.da.RF,area.acres*mean.RF_ft)
# LOK.stg.da.RF$RF.vol.UL <- with(LOK.stg.da.RF,area.acres*(UCI))
# LOK.stg.da.RF$RF.vol.LL <- with(LOK.stg.da.RF,area.acres*(LCI))
# 
# LOK.stg.da.RF$RF.vol.med <- with(LOK.stg.da.RF,area.acres*med.RF_ft)
# LOK.stg.da.RF$RF.vol.Q2 <- with(LOK.stg.da.RF,area.acres*(Q2.RF_ft))
# LOK.stg.da.RF$RF.vol.Q3 <- with(LOK.stg.da.RF,area.acres*(Q3.RF_ft))
# LOK.stg.da.RF$RF.vol.Q10 <- with(LOK.stg.da.RF,area.acres*(Q10.RF_ft))
# LOK.stg.da.RF$RF.vol.Q90 <- with(LOK.stg.da.RF,area.acres*(Q90.RF_ft))
# 
# LOK.stg.da.RF$RF.vol_30d <- zoo::rollapply(LOK.stg.da.RF$RF.vol,30,mean,align="right",fill=NA)
# LOK.stg.da.RF$RF.vol.UL_30d <- zoo::rollapply(LOK.stg.da.RF$RF.vol.UL,30,mean,align="right",fill=NA)
# LOK.stg.da.RF$RF.vol.LL_30d <- zoo::rollapply(LOK.stg.da.RF$RF.vol.LL,30,mean,align="right",fill=NA)

# Flows -------------------------------------------------------------------
LOK.Q.dbkeys <- data.frame(
  DBKEY = c("AL760","91656","91687","91686","91675","91668",
            "91513","91508","91510","02855",
            "DJ235","DJ239"),
  SITE = c("S65EX1","S65E","S84","S84X","S72","S71",
              "S354","S351","S352","L8.441",
           "S77","S308"),
  loc = c(rep("inflow_North",6),rep("outflow_South",4),
          "CRE","SLE")
)

LOK_Q_list <- lapply(LOK.Q.dbkeys$DBKEY, function(dbkey) {
  # Attempt to retrieve data and handle errors
  tryCatch({
    tmp <- DBHYDRO_daily(sdate, edate, dbkey)
    tmp$DBKEY <- as.character(dbkey)
    #setTxtProgressBar(pb, i)
    tmp
  }, error = function(e) {
    message(sprintf("Skipping DBKEY %s due to error: %s", dbkey, e$message))
    NULL  # Return NULL if there's an error
  })
})

# Remove any NULL elements (i.e., those that caused errors) from the list
LOK_Q_list <- Filter(Negate(is.null), LOK_Q_list)

loc.dir <- data.frame(loc = c("inflow_North", "outflow_South", "CRE", "SLE"),
                      flow.dir = c("Inflow","Outflow","CRE", "SLE"))
# loc.dir <- data.frame(loc = c("inflow_North", "outflow_South", "CRE", "SLE"),
#                       flow.dir = c("Inflow","Outflow",NA,NA))

LOK.Q.da <- do.call(rbind, LOK_Q_list)|>
  merge(LOK.Q.dbkeys, by = "DBKEY")|>
  merge(loc.dir,by="loc")|>
  mutate(Date.EST = date.fun(Date),
         flow.dir = ifelse(Data.Value<0,"Inflow",flow.dir)
         # flow.dir = ifelse(flow.dir=="Outflow"&Data.Value<0,"Inflow",flow.dir)
         # flow.dir = ifelse(flow.dir=="Outflow"&Data.Value<0,"Inflow","Outflow")
         )
# LOK.Q.da$flow.dir <- with(LOK.Q.da,ifelse(loc=="inflow_North","Inflow",as.character(flow.dir)))
# LOK.Q.da$Data.Value <- with(LOK.Q.da,ifelse(flow.dir%in%c("CRE","SLE")&Data.Value<0,0,Data.Value))

LOK.Q.da_total <- dcast(LOK.Q.da,Date.EST~flow.dir,
                        value.var = "Data.Value",
                        fun.aggregate = function(x) sum(abs(x),na.rm=T))|>
  mutate(month = as.numeric(format(Date.EST,"%m")),
         CY = as.numeric(format(Date.EST,"%Y")),
         day = as.numeric(format(Date.EST,"%d")),
         DOY = as.numeric(format(Date.EST,"%j")))

plot(CRE~Date.EST,LOK.Q.da_total)
plot(SLE~Date.EST,LOK.Q.da_total)
summary(LOK.Q.da_total)

LOK.Q.DOYstats <- ddply(LOK.Q.da_total,c("DOY"),summarise,
                        Inflow.mean = mean(Inflow,na.rm=T),
                        Inflow.median = median(Inflow,na.rm=T),
                        Inflow.Q10 = quantile(Inflow,na.rm=T,probs=c(0.10)),
                        Inflow.Q90 = quantile(Inflow,na.rm=T,probs=c(0.90)),
                        Outflow.mean = mean(Outflow,na.rm=T),
                        Outflow.median = median(Outflow,na.rm=T),
                        Outflow.Q10 = quantile(Outflow,na.rm=T,probs=c(0.10)),
                        Outflow.Q90 = quantile(Outflow,na.rm=T,probs=c(0.90)),
                        CRE.median = median(CRE,na.rm=T),
                        CRE.Q10 = quantile(CRE,na.rm=T,probs=c(0.10)),
                        CRE.Q90 = quantile(CRE,na.rm=T,probs=c(0.90)),
                        SLE.median = median(SLE,na.rm=T),
                        SLE.Q10 = quantile(SLE,na.rm=T,probs=c(0.10)),
                        SLE.Q90 = quantile(SLE,na.rm=T,probs=c(0.90)))




## Set up data for forecasts
ET.dat <- data.frame(Date.EST = seq(TODAY+(1*86400),EDate,"1 days"))|>
  mutate(DOY = as.numeric(format(Date.EST,"%j")))|>
  merge(overall_ETPI_mean,"DOY",sort=F)

RF.dat <- data.frame(Date.EST = seq(TODAY+(1*86400),EDate,"1 days"))|>
  mutate(DOY = as.numeric(format(Date.EST,"%j")))|>
  merge(overall_rf_mean,"DOY",sort=F)

Q.dat <- data.frame(Date.EST = seq(TODAY+(1*86400),EDate,"1 days"))|>
  mutate(DOY = as.numeric(format(Date.EST,"%j")))|>
  merge(LOK.Q.DOYstats,"DOY",sort=F)

LOK.stg.da_today <- subset(LOK.stg.da,Date.EST==TODAY-(1*86400))

s.cols <- adjustcolor(
  c("forestgreen","blue","indianred4","aquamarine3","goldenrod3","goldenrod3"),
  0.50)
leg.txt = c("CRE 2100 cfs; SLE 1400 cfs;\nEAA 0 cfs",
            "CRE 2100 cfs; SLE 1400 cfs;\nEAA Hist Median",
            "CRE 2100 cfs; SLE 1400 cfs;\nEAA Hist Median + 300 cfs (1 FEB)",
            "CRE 2100 cfs; SLE 700 cfs;\nEAA Hist Median + 300 cfs (1 FEB)",
            "CRE 2100 cfs; SLE 0 cfs;\nEAA Hist Median + 300 cfs (1 FEB)",
            "CRE 2100 cfs; SLE 150 cfs;\nEAA Hist Median + 300 cfs (1 FEB)"
            )

subset(LOK.stg.da,Date.EST==lake.rec)

Q.sum <- ddply(LOK.Q.da,c("loc","Date.EST"),summarise,TFlow = sum(abs(Data.Value),na.rm=T))
Q.sum$MA.14d <- with(Q.sum,ave(TFlow,loc,FUN = function(x) rollapply(x,width=14,FUN=mean, na.rm=T,align="right",fill=NA)))

# library(ggplot2)
# ggplot(subset(Q.sum,Date.EST>lake.rec-(2*86400)),aes(x=Date.EST,y=TFlow))+
#   geom_point()+
#   facet_wrap(~loc,scales="free")


```

At the start of the lake recovery period (`r format(lake.rec,"%b %d")`), lake Okeechobee stage was at `r subset(LOK.stg.da,Date.EST==lake.rec)$STG29` Ft NGVD29. Yesterday (`r format(YEST,"%b, %d %Y")`), lake Okeechobee stage was at `r subset(LOK.stg.da,Date.EST==YEST)$STG29` Ft NGVD29. As of yesterday, the 14-day moving average for inflows north and outflows east, west and south were `r round(subset(Q.sum,loc=="inflow_North"&Date.EST==YEST)$MA.14d)`, `r round(subset(Q.sum,loc=="SLE"&Date.EST==YEST)$MA.14d)`, `r round(subset(Q.sum,loc=="CRE"&Date.EST==YEST)$MA.14d)` and `r round(subset(Q.sum,loc=="outflow_South"&Date.EST==YEST)$MA.14d)`cfs. 

```{r Q,echo=FALSE,results='hide',fig.width=7,fig.height=6,fig.align='center',fig.cap="Daily and 14-day moving average discharge volumes for inflows north and outflows east, west and south"}
par(family="serif",mar=c(1,3,0.25,0.5),oma=c(3,2.5,1,0.1));
layout_matrix <- matrix(c(0,  1,  0, 
                          2,  0,  3, 
                          0,  4,  0), 
                        nrow = 3, byrow = TRUE)
layout(layout_matrix)#,heights=c(0.8,0.8,0.8),widths=c(0.8,0.8,0.8))

locs <- c("inflow_North", "CRE", "SLE", "outflow_South")
locs.labs <- c("Inflow North","Outflow West (CRE)","Outflow East (SLE)","Outflow South (EAA)")
maxQ <- aggregate(TFlow~loc,data=subset(Q.sum,Date.EST>lake.rec-(2*86400)),max,na.rm=T)|>
  mutate(TFlow = TFlow*1.1)

for(i in 1:4){
  ylim.val <- c(0,subset(maxQ,loc==locs[i])$TFlow);
  # by.y <- NA; 
  # ymaj <- seq(ylim.val[1],ylim.val[2],by.y);
  # ymin <- seq(ylim.val[1],ylim.val[2],by.y/2)
  ymaj <- heckbert_labs(ylim.val[1],ylim.val[2],5)
  ymin <- seq(ylim.val[1],ylim.val[2],mean(diff(ymaj))/2)
  xlim.val <- c(lake.rec-(2*86400),YEST+(14*86400)); xmaj <- seq(xlim.val[1],xlim.val[2],"30 days"); xmin <- seq(xlim.val[1],xlim.val[2],"15 days")
  
  tmp.dat <- subset(Q.sum,loc==locs[i])
  # tmp.dat[tmp.dat$Date.EST==YEST&tmp.dat$TFlow==0,"TFlow"] <- NA
  
  plot(TFlow~Date.EST,Q.sum,type="n",ann=F,axes=F,ylim=ylim.val,xlim=xlim.val)
  abline(h=ymaj,v=xmaj,lty=3,col="grey",lwd=0.5)
  with(tmp.dat,pt_line(Date.EST,TFlow,2,"lightblue",1,21,"dodgerblue1",pt.lwd = 0.1))
  lines(MA.14d~Date.EST,tmp.dat,col="red")
  # if(is.na(subset(tmp.dat,Date.EST==YEST)$TFlow)|subset(tmp.dat,Date.EST==YEST)$TFlow==0){
  #   points(MA.14d~Date.EST,subset(tmp.dat,Date.EST==YEST-86400),pch=19,col="red")
  #   with(subset(tmp.dat,Date.EST==YEST-86400),text(Date.EST,MA.14d,round(MA.14d),pos=4,offset=0.5,font=4,cex=0.75,col="red"))
  # }else{
    points(MA.14d~Date.EST,subset(tmp.dat,Date.EST==YEST),pch=19,col="red")
    with(subset(tmp.dat,Date.EST==YEST),text(Date.EST,MA.14d,round(MA.14d),pos=4,offset=0.5,font=4,cex=0.75,col="red")) 
  # }
  axis_fun(1,xmaj,xmin,format(xmaj,"%m-%d"),line=-0.5)
  axis_fun(2,ymaj,ymin,ymaj);box(lwd=1)
  mtext(side=3,locs.labs[i],font=2)
  if(i==2){mtext(side=2,line=3,"Discharge (cfs)")}
  if(i==4){mtext(side=1,line=2,"Date (Month-Day)")}
}
```



```{r setup2,echo=F}
sNums <- paste0("S",1:6)

fore.scen <- data.frame(scenario = sNums,
                        CRE = 2100,
                        SLE = c(rep(1400,3),700,0,150),
                        EAA = c(-1,0,rep(300,4)))

EAA_add <- data.frame(Date.EST = seq(TODAY+(1*86400),EDate,"1 days"))
  # mutate(AddQ = ifelse(Date.EST>date.fun("2025-02-01"),300,0))

HMF.UCIs <- data.frame(Date.EST = seq(TODAY+(1*86400),EDate,"1 days"));# stores stage forecast for all scenarios
HMF.LCIs <- data.frame(Date.EST = seq(TODAY+(1*86400),EDate,"1 days"));# stores stage forecast for all scenarios
knitr::opts_chunk$set(echo = TRUE,
                      fig.align='center')


LOK_HMF.base <- forFUN_scenario(
    CRE.Q = cfs.to.acftd(Q.dat$CRE.median),
    SLE.Q = cfs.to.acftd(Q.dat$SLE.median),
    EAA.Q = cfs.to.acftd(Q.dat$Outflow.median), 
    # EAA.Q = if(subset(fore.scen,scenario==sNums[i])$EAA == 0){rep(0,nrow(EAA_add))}else{cfs.to.acftd(Q.dat$Outflow.median+EAA_add$AddQ)}, 
    inflow.Q = cfs.to.acftd(Q.dat$Inflow.median), 
    ET =  ET.dat$med.ETPI_ft,
    RF = RF.dat$med.RF_ft,
    STG = LOK.stg.da_today$STG29)
# LOK_HMF.base.UCI <- forFUN_scenario(
#     CRE.Q = cfs.to.acftd(Q.dat$CRE.Q90),
#     SLE.Q = cfs.to.acftd(Q.dat$SLE.Q90),
#     EAA.Q = cfs.to.acftd(Q.dat$Outflow.Q90),
#     inflow.Q = cfs.to.acftd(Q.dat$Inflow.Q90),
#     ET =  ET.dat$Q90.ETPI_ft,
#     RF = RF.dat$Q90.RF_ft,
#     STG = LOK.stg.da_today$STG29)
# LOK_HMF.base.LCI <- forFUN_scenario(
#     CRE.Q = cfs.to.acftd(Q.dat$CRE.Q10),
#     SLE.Q = cfs.to.acftd(Q.dat$SLE.Q10),
#     EAA.Q = cfs.to.acftd(Q.dat$Outflow.Q10),
#     inflow.Q = cfs.to.acftd(Q.dat$Inflow.Q10),
#     ET =  ET.dat$Q10.ETPI_ft,
#     RF = RF.dat$Q10.RF_ft,
#     STG = LOK.stg.da_today$STG29)

LOK_HMF.base.UCI <- forFUN_scenario(
    CRE.Q = cfs.to.acftd(Q.dat$CRE.Q90),
    SLE.Q = cfs.to.acftd(Q.dat$SLE.Q10),
    EAA.Q = cfs.to.acftd(Q.dat$Outflow.Q10),
    inflow.Q = cfs.to.acftd(Q.dat$Inflow.Q90),
    ET =  ET.dat$Q10.ETPI_ft,
    RF = RF.dat$Q90.RF_ft,
    STG = LOK.stg.da_today$STG29)
LOK_HMF.base.LCI <- forFUN_scenario(
    CRE.Q = cfs.to.acftd(Q.dat$CRE.Q90),
    SLE.Q = cfs.to.acftd(Q.dat$SLE.Q10),
    EAA.Q = cfs.to.acftd(Q.dat$Outflow.Q90),
    inflow.Q = cfs.to.acftd(Q.dat$Inflow.Q10),
    ET =  ET.dat$Q90.ETPI_ft,
    RF = RF.dat$Q10.RF_ft,
    STG = LOK.stg.da_today$STG29)


```

```{r, echo=FALSE,results='asis'}

for(i in 1:nrow(fore.scen)){
  # Create header for each tab
  cat(sprintf("\n### %s\n", paste("Scenario",i)))
  
  
  EAA_add$AddQ <- if(subset(fore.scen,scenario==sNums[i])$EAA <= 0){
    Q.dat$Outflow.median*subset(fore.scen,scenario==sNums[i])$EAA
  }else{
      ifelse(EAA_add$Date.EST>date.fun("2025-02-01"),300,0)
  }
  EAA_add$AddQ.UCI <- if(subset(fore.scen,scenario==sNums[i])$EAA <= 0){
    Q.dat$Outflow.Q90*subset(fore.scen,scenario==sNums[i])$EAA
  }else{
      ifelse(EAA_add$Date.EST>date.fun("2025-02-01"),300,0)
  }
  EAA_add$AddQ.LCI <- if(subset(fore.scen,scenario==sNums[i])$EAA <= 0){
    Q.dat$Outflow.Q10*subset(fore.scen,scenario==sNums[i])$EAA
  }else{
      ifelse(EAA_add$Date.EST>date.fun("2025-02-01"),300,0)
    }
                                      
  
  LOK_HMF <- forFUN_scenario(
    CRE.Q = cfs.to.acftd(subset(fore.scen,scenario==sNums[i])$CRE)*rep(Q.fac,num.weeks),
    SLE.Q = cfs.to.acftd(subset(fore.scen,scenario==sNums[i])$SLE)*rep(Q.fac,num.weeks),
    EAA.Q = cfs.to.acftd(Q.dat$Outflow.median+EAA_add$AddQ), 
    # EAA.Q = if(subset(fore.scen,scenario==sNums[i])$EAA == 0){rep(0,nrow(EAA_add))}else{cfs.to.acftd(Q.dat$Outflow.median+EAA_add$AddQ)}, 
    inflow.Q = cfs.to.acftd(Q.dat$Inflow.median), 
    ET =  ET.dat$med.ETPI_ft,
    RF = RF.dat$med.RF_ft,
    STG = LOK.stg.da_today$STG29)
  LOK_HMF$scenario <- sNums[i]
  
  assign(paste0("LOK_HMF_S",i),LOK_HMF)
  ## Wetter Scenarios
  LOK_HMF.UCI <- forFUN_scenario(
    CRE.Q = cfs.to.acftd(subset(fore.scen,scenario==sNums[i])$CRE)*rep(Q.fac,num.weeks),
    SLE.Q = cfs.to.acftd(subset(fore.scen,scenario==sNums[i])$SLE)*rep(Q.fac,num.weeks),
    EAA.Q = cfs.to.acftd(Q.dat$Outflow.Q10+EAA_add$AddQ.LCI),
    # EAA.Q = cfs.to.acftd(Q.dat$Outflow.Q90+EAA_add$AddQ.UCI),
    inflow.Q = cfs.to.acftd(Q.dat$Inflow.Q90),
    ET =  ET.dat$Q10.ETPI_ft,
    RF = RF.dat$Q90.RF_ft,
    STG = LOK.stg.da_today$STG29)
  ## Drier Scenarios
  LOK_HMF.LCI <- forFUN_scenario(
    CRE.Q = cfs.to.acftd(subset(fore.scen,scenario==sNums[i])$CRE)*rep(Q.fac,num.weeks),
    SLE.Q = cfs.to.acftd(subset(fore.scen,scenario==sNums[i])$SLE)*rep(Q.fac,num.weeks),
    EAA.Q = cfs.to.acftd(Q.dat$Outflow.Q90+EAA_add$AddQ.UCI),# +EAA_add$AddQ.LCI),# cfs.to.acftd(pmax(0,Q.dat$Outflow.Q10+EAA_add$AddQ.LCI)),
    inflow.Q = cfs.to.acftd(Q.dat$Inflow.Q10),
    ET =  ET.dat$Q90.ETPI_ft,
    RF = RF.dat$Q10.RF_ft,
    STG = LOK.stg.da_today$STG29)
  # 
  # plot(Stage~Date_forecast,LOK_HMF)
  # lines(Stage~Date_forecast,LOK_HMF.UCI)
  # lines(Stage~Date_forecast,LOK_HMF.LCI)
  # 
  # 
  tmp.UCI <- LOK_HMF.UCI[,c("Date_forecast","Stage")];colnames(tmp.UCI) <- c("Date.EST",sNums[i])
  tmp.LCI <- LOK_HMF.LCI[,c("Date_forecast","Stage")];colnames(tmp.LCI) <- c("Date.EST",sNums[i])
  HMF.UCIs <- merge(HMF.UCIs,tmp.UCI,"Date.EST")
  HMF.LCIs <- merge(HMF.LCIs,tmp.LCI,"Date.EST")
  
  # plot(LOK_HMF.LCI$Stage~LOK_HMF.UCI$Stage);abline(0,1)
  # plot(EAA~Date_forecast,LOK_HMF.UCI,ylim=c(0,30000),type="l")
  # lines(EAA~Date_forecast,LOK_HMF.LCI)
  
  par(family="serif",mar=c(2,3,0.25,0.5),oma=c(2,1,1,0.5));
  layout(matrix(1:2,1,2),widths=c(1,0.5))

  xlim.val <- date.fun(c("2024-11-20","2025-04-30"));by.x <- 10;
  xmaj <- seq(xlim.val[1],xlim.val[2],"2 months");
  xmin <- seq(xlim.val[1],xlim.val[2],"1 months")
  ylim.val <- c(10,17.5);by.y <- 2;ymaj <- seq(ylim.val[1],ylim.val[2],by.y);ymin <- seq(ylim.val[1],ylim.val[2],by.y/2)
  # ymaj <- labeling::heckbert(ylim.val[1],ylim.val[2],6)

  plot(STG29~Date.EST,LOK.stg.da,ylim=ylim.val,xlim=xlim.val,type="n",ann=F,axes=F)
  abline(h=ymaj,v=xmaj,lwd=0.5,col="grey",lty=3)
  lines(ZONE.A~Date,LOSOM.sch.bk,lwd=1.5,col="black")
  lines(ZONE.BC~Date,LOSOM.sch.bk,lwd=1.5,col="black")
  lines(ZONE.D~Date,LOSOM.sch.bk,lwd=1.5,col="grey")
  lines(STG29~Date.EST,LOK.stg.da,lwd=1,col="red",lty=1)
  # shaded.range(LOK_HMF.UCI$Date_forecast,LOK_HMF_S1.LCI$Stage,LOK_HMF_S1.UCI$Stage,s.cols[i],lty=0)
  lines(Stage~Date_forecast,LOK_HMF,lwd=2,col=s.cols[i],lty=1)
  lines(Stage~Date_forecast,LOK_HMF.UCI,col=s.cols[i],lty=2,lwd=1)
  lines(Stage~Date_forecast,LOK_HMF.LCI,col=s.cols[i],lty=2,lwd=1)
  abline(h=12,col="hotpink",lwd=2,lty=2)
  abline(h=11.5,col="lightgreen",lwd=2,lty=2)
  axis_fun(1,xmaj,xmin,format(xmaj,"%m-%Y"),line=-0.5)
  axis_fun(2,ymaj,ymin,ymaj)
  box(lwd=1)
  mtext(side=1,"Month",line=2,cex=1.25)
  mtext(side=2,"Stage Elevation\n(Feet, NGVD29)",line=2,cex=1)

  par(mar=c(2,0.5,0.25,0.25))
  plot(0:1,0:1,type="n",ann=F,axes=F)

  legend("center",
         legend = c("Current Stage",leg.txt[i]),
         pch=c(NA),lty=c(1),lwd=2,
         col=c("red",s.cols[i]),#,"hotpink","lightgreen"),
         pt.bg=c(NA),pt.cex=1,
         ncol=1,cex=0.7,bty="n",y.intersp=1.5,x.intersp=0.75,xjust=0.5,yjust=0.5)
  mtext(side=1,line=-2,adj=0,"- Estuary discharges based on\n 2-week avg pulse discharges\n- Historic median rainfall\n- Historic median ET",cex=0.75)
  
  cat(sprintf("<center>Lake Okeechobee Stage forecast under scenario # %s (wetter (upper line) and drier (lower line) conditions).</center>", i))
  # cat(sprintf("<center>Lake Okeechobee Stage forecast (with 10th to 90th percentile band) under scenario # %s</center>", i))
  
  cat("<br>")
  
  LOK_HMF|>
  download_this(
    output_name = "output",
    output_extension = ".xlsx",
    button_label = "Scenario Forecast Output",
    button_type = "primary",
    has_icon = TRUE,
    icon = "fa fa-file-excel"
  )|>
    print()

  
  cat("\n\n")
}
```

### Base
```{r Base S,echo=FALSE,results='hide',fig.width=7,fig.height=5,fig.align='center',fig.cap="Base lake Okeechobee Stage forecast using historical data (wetter (upper line) and drier (lower line) conditions)."}
par(family="serif",mar=c(2,3,0.25,0.5),oma=c(2,1,1,0.5));
layout(matrix(1:2,1,2),widths=c(1,0.5))

xlim.val=date.fun(c("2024-11-20","2025-04-30"));by.x=10;xmaj=seq(xlim.val[1],xlim.val[2],"2 months");xmin=seq(xlim.val[1],xlim.val[2],"1 months")
ylim.val=c(10,17.5);by.y=2;ymaj=seq(ylim.val[1],ylim.val[2],by.y);ymin=seq(ylim.val[1],ylim.val[2],by.y/2)

plot(STG29~Date.EST,LOK.stg.da,ylim=ylim.val,xlim=xlim.val,type="n",ann=F,axes=F)
abline(h=ymaj,v=xmaj,lwd=0.5,col="grey",lty=3)
lines(ZONE.A~Date,LOSOM.sch.bk,lwd=1.5,col="black")
lines(ZONE.BC~Date,LOSOM.sch.bk,lwd=1.5,col="black")
lines(ZONE.D~Date,LOSOM.sch.bk,lwd=1.5,col="grey")
lines(STG29~Date.EST,LOK.stg.da,lwd=1,col="red",lty=1)
lines(Stage~Date_forecast,LOK_HMF.base,lwd=1,col="black",lty=1)
lines(Stage~Date_forecast,LOK_HMF.base.LCI,lwd=1,col="black",lty=2)
lines(Stage~Date_forecast,LOK_HMF.base.UCI,lwd=1,col="black",lty=2)
abline(h=12,col="hotpink",lwd=2,lty=2)
abline(h=11.5,col="lightgreen",lwd=2,lty=2)
axis_fun(1,xmaj,xmin,format(xmaj,"%m-%Y"),line=-0.5)
axis_fun(2,ymaj,ymin,ymaj)
box(lwd=1)
mtext(side=1,"Month",line=2,cex=1.25)
mtext(side=2,"Stage Elevation\n(Feet, NGVD29)",line=2,cex=1)

par(mar=c(2,0.5,0.25,0.25))
plot(0:1,0:1,type="n",ann=F,axes=F)
legend("center",
       legend = "Historic Observed Data",
       pch=c(NA),lty=c(1),lwd=2,
       col=c("black"),#,"hotpink","lightgreen"),
       pt.bg=c(NA),pt.cex=1,
       ncol=1,cex=0.7,bty="n",y.intersp=2,x.intersp=0.75,xjust=0.5,yjust=0.5)
# mtext(side=1,line=-2,adj=0,"- Estuary discharges based on\n 2-week avg pulse discharges\n- Assumes no rainfall\n- Historic median ET",cex=0.75)
```

### All Scenarios
```{r all S,echo=FALSE,results='hide',fig.width=7,fig.height=5,fig.align='center',fig.cap="Lake Okeechobee Stage forecast under all scenarios."}
# HMF.UCIs$Upper.vals <- apply(HMF.UCIs[,2:ncol(HMF.UCIs)],1,max,na.rm=T)
# HMF.LCIs$Lower.vals <- apply(HMF.LCIs[,2:ncol(HMF.LCIs)],1,min,na.rm=T)


par(family="serif",mar=c(2,3,0.25,0.5),oma=c(2,1,1,0.5));
layout(matrix(1:2,1,2),widths=c(1,0.5))

xlim.val=date.fun(c("2024-11-20","2025-04-30"));by.x=10;xmaj=seq(xlim.val[1],xlim.val[2],"2 months");xmin=seq(xlim.val[1],xlim.val[2],"1 months")
ylim.val=c(10,17.5);by.y=2;ymaj=seq(ylim.val[1],ylim.val[2],by.y);ymin=seq(ylim.val[1],ylim.val[2],by.y/2)

plot(STG29~Date.EST,LOK.stg.da,ylim=ylim.val,xlim=xlim.val,type="n",ann=F,axes=F)
abline(h=ymaj,v=xmaj,lwd=0.5,col="grey",lty=3)
lines(ZONE.A~Date,LOSOM.sch.bk,lwd=1.5,col="black")
lines(ZONE.BC~Date,LOSOM.sch.bk,lwd=1.5,col="black")
lines(ZONE.D~Date,LOSOM.sch.bk,lwd=1.5,col="grey")
lines(STG29~Date.EST,LOK.stg.da,lwd=1,col="red",lty=1)
lines(Stage~Date_forecast,LOK_HMF.base,lwd=1,col="black",lty=1)
for(k in 1:nrow(fore.scen)){
  tmp.dat <- get(paste("LOK_HMF",sNums[k],sep="_"))
  lines(Stage~Date_forecast,tmp.dat,lwd=2,col=s.cols[k],lty=1)
  
}
# lines(Lower.vals~Date.EST,HMF.LCIs,lwd=1,col="black",lty=2)
# lines(Upper.vals~Date.EST,HMF.UCIs,lwd=1,col="black",lty=2)
abline(h=12,col="hotpink",lwd=2,lty=2)
abline(h=11.5,col="lightgreen",lwd=2,lty=2)
axis_fun(1,xmaj,xmin,format(xmaj,"%m-%Y"),line=-0.5)
axis_fun(2,ymaj,ymin,ymaj)
box(lwd=1)
mtext(side=1,"Month",line=2,cex=1.25)
mtext(side=2,"Stage Elevation\n(Feet, NGVD29)",line=2,cex=1)

par(mar=c(2,0.5,0.25,0.25))
plot(0:1,0:1,type="n",ann=F,axes=F)
legend("center",
       legend = c("Historic",leg.txt),
       pch=c(NA),lty=c(rep(1,6),2),lwd=2,
       col=c(c("black",s.cols)),#,"hotpink","lightgreen"),
       pt.bg=c(NA),pt.cex=1,
       ncol=1,cex=0.6,bty="n",y.intersp=2,x.intersp=0.75,xjust=0.5,yjust=0.5)
mtext(side=1,line=-2,adj=0,"- Estuary discharges based on\n 2-week avg pulse discharges\n- Historic median rainfall\n- Historic median ET",cex=0.75)
```

## Data Sources {#datasource}

All data were retrieved from SFWMD DBhydro between `r format(dates[1],"%d %b %Y")` and `r format(dates[2],"%d %b %Y")` from the following DBKeys. 

```{r ,echo=F}
meta.dat <- DBHYDRO.meta.byDBKEY(c(LOK.da.dbkeys$DBKEY,LOK.etpi.dbkeys$DBKEY,LOK.rf.dbkeys$DBKEY,LOK.Q.dbkeys$DBKEY))
meta.dat <- meta.dat[match(c(LOK.da.dbkeys$DBKEY,LOK.etpi.dbkeys$DBKEY,LOK.rf.dbkeys$DBKEY,LOK.Q.dbkeys$DBKEY),meta.dat$DBKEY),]

meta.dat[,c(1:9,20)]|>
  flextable()|>
  fontsize(size=9,part="body")|>
  fontsize(size=11,part="header")|>
  padding(padding=1,part="all")|>
  autofit()
```

<br>